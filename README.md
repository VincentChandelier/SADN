# SADN: Learned Light Field Image Compression with Spatial-Angular Decorrelation 
  This repository contains the code for reproducing the results with trained models, in the following paper:
  Official code o f paper：[SADN: Learned Light Field Image Compression with Spatial-Angular Decorrelation.arxiv](https://arxiv.org/abs/2202.10837), ICASSP 2020
  
Kedeng Tong, Xin Jin, Chen Wang, Fan Jiang 

# Paper Summury:
Light field image becomes one of the most promising media types for immersive video applications. In this paper, we propose a novel end-to-end spatial-angular-decorrelated network (SADN) for high-efficiency light field image compression. Different from the existing methods that exploit either spatial or angular consistency in the light field image, SADN decouples the angular and spatial information by dilation convolution and stride convolution in spatialangular interaction, and performs feature fusion to compress spatial and angular information jointly. To train a stable and robust algorithm, a large-scale dataset consisting of 7549 light field images is proposed and built. The proposed method provides 2.137 times and 2.849 times higher compression efficiency relative to H.266/VVC and H.265/HEVC inter coding, respectively. It also outperforms the end-to-end image compression networks by an average of 79.6% bitrate saving with much higher subjective quality and light field consistency. 

# PINet： A large scale image dataset of a hand-held light Field camera is proposed
Description: We propose a new LF image database called “PINet” inheriting the hierarchical structure from WordNet. It 
consists of 7549 LIs captured by Lytro Illum, which is much larger than the existing databases. The images are manually annotated to 178 categories according to WordNet, such as cat, camel, bottle, fans, etc. The registered depth maps are also provided. Each image is generated by processing the raw LI from the camera by Light Field Toolbox v0.4 for demosaicing and devignetting. 

## Some central SAIs of LF images in the dataset. 

.![](https://github.com/VincentChandelier/SADN/blob/main/PINet/Central_Subapertures.png)

[The central-SAIs and registered depth maps](https://cloud.tsinghua.edu.cn/d/d47ad68552ec408eac94/  ) are available for previewing.

The raw Light field Images is available to download. (https://pan.baidu.com/s/1ebpt2K6F7-DOB42_Y2ZaDg Extraction code：d4l8)

The decoding code with LFtoolbox0.4 and  related camera parameters is available to download.(https://pan.baidu.com/s/1DsTL2ftKBrnp-nKnJQkilQ  Extraction code：5nxt)
If you want to explore the PINet or to produces your own training data, please follow the readme in the folder. 

For testing, the light field raw images and macro-images are provided. (https://pan.baidu.com/s/1JLv5oAax8j9xrzqFEY5__Q 
Extraction code：a832)


# Network
.![](https://github.com/VincentChandelier/SADN/blob/main/RDdata/Network.png)

# Evaluation Results
.![](https://github.com/VincentChandelier/SADN/blob/main/RDdata/RD.png)

#Usage

## Environment
   This code is based on the [CompressAI](https://github.com/InterDigitalInc/CompressAI).
## Train Usage
   ```
   cd Code
   python train.py -d dataset --N 48 --angRes 13 --n_blocks 1 -e 100 -lr 1e-4 -n 20  --lambda 3e-3 --batch-size 8  --test-batch-size 8 --aux-learning-rate 1e-3 --patch-size 832 832 --cuda --save --seed 1926 --gpu-id  0,1,2,3 --savepath   ./checkpoint
   ```
   The training patches I used for training is available (https://pan.baidu.com/s/1-nCg_zbSIVZZiiQ996LLTQ 
Extraction code：zhto)
## Update the entropy model
```
   python updata.py checkpoint_path -n checkpoint
```
   We will provide the checkpoint soon.
## Test 
Since the full test images are too large, I only upload a patch of the test image in Code/dataset/test
```
  python Inference.py --dataset/test --output_path Result_dir -p checkpoint_path
```

# Notes
This implementations are not original codes of our ICASSP2022 paper, because original code is based on Tensorflow 2.4.0 and many features have been removed. This repo is a re-implementation, but the core codes are almost the same and results are also consistent with original results. 

If you think it is useful for your reseach, please cite our ICASSP2020 paper. Our original RD data in the paper is contained in the folder RDdata/.

```
@article{tong2022sadn,
  title={SADN: Learned Light Field Image Compression with Spatial-Angular Decorrelation},
  author={Tong, Kedeng and Jin, Xin and Wang, Chen and Jiang, Fan},
  journal={arXiv preprint arXiv:2202.10837},
  year={2022}
}
```

## EPLF dataset
[EPLF](https://www.epfl.ch/labs/mmspg/downloads/epfl-light-field-image-dataset/)
```
@inproceedings{rerabek2016new,
  title={New light field image dataset},
  author={Rerabek, Martin and Ebrahimi, Touradj},
  booktitle={8th International Conference on Quality of Multimedia Experience (QoMEX)},
  number={CONF},
  year={2016}
}
```
## ICME 12 LF dataset
```
@article{rerabek2016icme,
  title={Icme 2016 grand challenge: Light-field image compression},
  author={Rerabek, Martin and Bruylants, Tim and Ebrahimi, Touradj and Pereira, Fernando and Schelkens, Peter},
  journal={Call for proposals and evaluation procedure},
  year={2016}
}
```
